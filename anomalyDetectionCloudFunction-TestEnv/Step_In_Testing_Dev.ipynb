{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Step In Testing Dev.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNK+Z8qAzZpjBUzBXi+GgyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microdinosaur/10kAnalysis/blob/master/anomalyDetectionCloudFunction-TestEnv/Step_In_Testing_Dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4843IIxMUepb",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTeUSColUYWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime, timedelta\n",
        "import datetime as dt\n",
        "import random\n",
        "import os\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np                               # vectors and matrices\n",
        "import pandas as pd                              # tables and data manipulations\n",
        "from google.cloud import bigquery\n",
        "import google.cloud.bigquery as bq\n",
        "import ast\n",
        "import pyarrow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyg9ika5Ukaa",
        "colab_type": "text"
      },
      "source": [
        "# Set Env Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1fWnUwSUjlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sql = \"\"\"SELECT myDate, source, medium, landingPage, sessions, goalCompletions  FROM `michaelr-workspace.anomalyDetectionRoot.cbtNuggets` WHERE myDate between DATE_SUB(current_date(), INTERVAL 400 DAY) and current_date()\"\"\" #@param\n",
        "id = 'michaelr-workspace' #@param {type: \"string\"}\n",
        "toClean = True #@param\n",
        "colToClean = 'landingPage' #@param {type: \"string\"}\n",
        "dateColumn = 'myDate' #@param {type: \"string\"}\n",
        "dimColumnOne = 'landingPage' #@param {type: \"string\"}\n",
        "dimColumnTwo = 'source' #@param {type: \"string\"}\n",
        "metricColumn = 'sessions' #@param {type: \"string\"}\n",
        "finalTable = 'BREAK' #@param {type: \"string\"}\n",
        "lpCount = 100 #@param {type: \"number\"}\n",
        "series_length = 365 #@param {type: \"number\"}\n",
        "window = 8 #@param {type: \"number\"}\n",
        "focusList = \"['www.cbtnuggets.com/',  'www.cbtnuggets.com/learn',  '(not set)',  'www.cbtnuggets.com/login',  'www.cbtnuggets.com/search']\" #@param {type: \"string\"}\n",
        "focusList = ast.literal_eval(focusList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6OSlNlXgnCn",
        "colab_type": "text"
      },
      "source": [
        "# Get tables for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvNaKKHPgpQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keyName = 'michaelROwnerKey.json'\n",
        "client = bq.Client.from_service_account_json(keyName)\n",
        "df = client.query(sql, project=id).to_dataframe()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBKF3CPqi0fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfbq = df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l03Wq14DYzsK",
        "colab_type": "text"
      },
      "source": [
        "# Set Functions Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuAU6lJYY4II",
        "colab_type": "text"
      },
      "source": [
        "## Data Frame Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCtw0Is0Y58C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepSingleDataFrame(df, clean, cleanCol, dateCol, metric, *dims):\n",
        "    dfFun = df.copy()\n",
        "    del df\n",
        "    if clean == True:\n",
        "        dfFun[colToClean] = dfFun[colToClean].str.replace('\\?.*', '')  # Clean Query Strings from LPs\n",
        "    dfOut = dfFun.copy()\n",
        "    del dfFun\n",
        "    cols = []\n",
        "    cols.append(dateCol)\n",
        "    for i in dims:\n",
        "        cols.append(i)\n",
        "    cols.append(metric)\n",
        "    dfOut = dfOut[cols]\n",
        "    return dfOut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGlq4LZrY_4W",
        "colab_type": "text"
      },
      "source": [
        "## Filter Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4ZrYnEOY-WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filterDim(priorityPages, df, filterDim):\n",
        "    dfFiltered = df.loc[df[filterDim].isin(priorityPages)]\n",
        "    return dfFiltered"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQlweB4LZFzz",
        "colab_type": "text"
      },
      "source": [
        "## Create now and later tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXfVoxfvZDSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nowAndLater(df, date, met, start, end, startYoY, endYoY, *dims):\n",
        "    ### Now ###\n",
        "    dfNow = df[df[date].between(start, end)]  # filter to date\n",
        "    # create grouping index\n",
        "    groups = []\n",
        "    groups.append(date)\n",
        "    for i in dims:\n",
        "        groups.append(i)\n",
        "\n",
        "    dfNow = dfNow.groupby(groups).sum()\n",
        "\n",
        "    dfNow.reset_index(inplace=True)\n",
        "\n",
        "    dfNow[date] = pd.to_datetime(dfNow[date], format='%Y-%m-%d')\n",
        "\n",
        "    dfNowFinal = dfNow.set_index(groups, inplace=False)\n",
        "\n",
        "    ### Then ###\n",
        "    dfThen = df[df[date].between(startYoY, endYoY)]  # filter to date\n",
        "    # create grouping index\n",
        "    groups = []\n",
        "    groups.append(date)\n",
        "    for i in dims:\n",
        "        groups.append(i)\n",
        "\n",
        "    dfThen = dfThen.groupby(groups).sum()\n",
        "    dfThen.reset_index(inplace=True)\n",
        "    dfNow[date] = pd.to_datetime(dfThen[date], format='%Y-%m-%d')\n",
        "    dfThenFinal = dfThen.set_index(groups, inplace=False)\n",
        "\n",
        "    return dfNowFinal, dfThenFinal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb_lqDmQb4sd",
        "colab_type": "text"
      },
      "source": [
        "## Get Intersections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODLJLRNGZNMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def intersection(lst1, lst2):\n",
        "    return list(set(lst1) & set(lst2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO2F8njZb6K8",
        "colab_type": "text"
      },
      "source": [
        "## Get Bounds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYeYcvruZQL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getBounds(series, window, rollingMean, scale=1, lowerBound=True):\n",
        "\n",
        "    #print(\"Get Bounds - Series: \", series)\n",
        "    #print(\"Get Bounds - Window: \", window)\n",
        "    #print(\"Get Bounds - rollingMean: \", rollingMean)\n",
        "    if lowerBound == True:\n",
        "        boundAdjuster = -1\n",
        "    else:\n",
        "        boundAdjuster = 1\n",
        "\n",
        "    mae = mean_absolute_error(series[window:], rollingMean[window:])  # Get MAE\n",
        "\n",
        "    deviation = np.std(series[window:] - rollingMean[window:])  # Set Deviation\n",
        "\n",
        "    bound = rollingMean + boundAdjuster * \\\n",
        "    \t(mae + scale * deviation)  # Set Lower Bound\n",
        "\n",
        "    return bound"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGz50AJxb0ie",
        "colab_type": "text"
      },
      "source": [
        "## Get Anomaly Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsRa_PuvZWDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getAnomalies2(series, window, upperBound, lowerBound, upperBoundYOY=[], lowerBoundYOY=[], lbound=True, isYOY=True):\n",
        "    try:\n",
        "        anomalies = pd.DataFrame(\n",
        "            index=series.index, columns=series.columns)  # Set Anomalies\n",
        "        #print(\"Length of Anomalies: \", len(anomalies))\n",
        "        anomalies[series < lowerBound] = series[series < lowerBound]\n",
        "        # print(\"Error Handling: anomalies lower\",anomalies)\n",
        "        anomalies[series > upperBound] = series[series > upperBound]\n",
        "        # print(\"Error Handling: anomalies upper\",anomalies)\n",
        "        suspect_lower = anomalies[series < lowerBound].dropna(how='all')\n",
        "        # print(\"Error Handling: suspect_lower\", suspect_lower,\"\\n\")\n",
        "        suspect_upper = anomalies[series > upperBound].dropna(how='all')\n",
        "        # print(\"Error Handling: suspect_upper\", suspect_upper,\"\\n\")\n",
        "\n",
        "        if isYOY == True:\n",
        "            #print(\"Get Anomalies  - isYOY is True\")\n",
        "            anomaliesYOY = pd.DataFrame(\n",
        "            \tindex=series.index, columns=series.columns)\n",
        "            #print(\"Error Handling: anomaliesYOY\",anomaliesYOY)\n",
        "            #print(\"Error Handling: series\", series)\n",
        "            anomaliesYOY[series <\n",
        "                         lowerBoundYOY] = series[series < lowerBoundYOY]\n",
        "            anomaliesYOY[series > upperBoundYOY] = series[series >\n",
        "                                                          upperBoundYOY]  # REMOVE UPPER BOUNDS CHECK\n",
        "\n",
        "            suspect_lowerYOY = anomaliesYOY[series <\n",
        "                                            lowerBoundYOY].dropna(how='all')\n",
        "            # print(\"Error Handling: suspect_lowerYOY\", suspect_lowerYOY)\n",
        "            suspect_upperYOY = anomaliesYOY[series > upperBoundYOY].dropna(\n",
        "            \thow='all')  # REMOVE UPPER BOUNDS CHECK\n",
        "            suspectYOY = anomaliesYOY.dropna(how='all')\n",
        "\n",
        "            ## Merge both years\n",
        "            realAnomaliesLower = pd.merge(\n",
        "            \tsuspect_lower, suspect_lowerYOY, right_index=True, left_index=True)\n",
        "            realAnomaliesUpper = pd.merge(\n",
        "            \tsuspect_upper, suspect_upperYOY, right_index=True, left_index=True)\n",
        "\n",
        "            if lbound == True:\n",
        "                  return realAnomaliesLower\n",
        "            if lbound == False:\n",
        "                  return realAnomaliesUpper\n",
        "\n",
        "        elif isYOY == False:\n",
        "            realAnomaliesLower = pd.merge(\n",
        "            \tsuspect_lower, suspect_lower, right_index=True, left_index=True)\n",
        "            realAnomaliesUpper = pd.merge(\n",
        "            \tsuspect_upper, suspect_upper, right_index=True, left_index=True)\n",
        "\n",
        "            if lbound == True:\n",
        "                return realAnomaliesLower\n",
        "            if lbound == False:\n",
        "                return realAnomaliesUpper\n",
        "\n",
        "    except:\n",
        "        thisFailed = series['sessions'] = np.nan\n",
        "        return anomalies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMUYlJBrb_pp",
        "colab_type": "text"
      },
      "source": [
        "#OG Handler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHQahHIocD0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def handler(dfbq,colToClean, dateColumn,dimColumnOne,dimColumnTwo,metricColumn,toClean=True, lpCount=100, series_length=365, window=8):\n",
        "\n",
        "    #Generate Query & initial table\n",
        "    dfCopy = dfbq.copy()\n",
        "    del dfbq\n",
        "    print(\"1. BigQuery Table Collected\")\n",
        "\n",
        "    # Create Initial DataFrame - Cleaning Query Strings if Applicable\n",
        "    #def prepSingleDataFrame(df, clean, cleanCol, dateCol, metric, *dims):\n",
        "    df = prepSingleDataFrame(dfCopy, toClean, colToClean,\n",
        "                             dateColumn, metricColumn, dimColumnOne, dimColumnTwo)\n",
        "    print(\"\\n2. Data Frame Created\")\n",
        "\n",
        "    # Get Filter list for primary dimension\n",
        "    #focusList = focus(df, dimColumnOne, metricColumn, n=lpCount)\n",
        "    #print(\"\\n3. Focus list created of top \", lpCount, dimColumnOne)\n",
        "    \n",
        "\n",
        "    # Update table to only include focusList items\n",
        "    dfFiltered = filterDim(focusList, df, dimColumnOne)\n",
        "    print(\"\\n4. Filtered data to top \", lpCount, dimColumnOne)\n",
        "    del df\n",
        "\n",
        "    # Set Dates\n",
        "    end_date = pd.to_datetime(\n",
        "    \t(datetime.now() - timedelta(1)).strftime('%Y-%m-%d')).date()\n",
        "    start_date = pd.to_datetime(\n",
        "    \t(datetime.now() - timedelta(30)).strftime('%Y-%m-%d')).date()\n",
        "    start_dateYOY = pd.to_datetime(\n",
        "    \t(datetime.now() - timedelta(396)).strftime('%Y-%m-%d')).date()  # test at 396,365\n",
        "    end_dateYOY = pd.to_datetime(\n",
        "    \t(datetime.now() - timedelta(366)).strftime('%Y-%m-%d')).date()\n",
        "    print(\"\\n5. Created Data ranges\")\n",
        "\n",
        "    # Create Current Year Table and Previous Year Table\n",
        "    dfNow, dfThen = nowAndLater(dfFiltered, dateColumn, metricColumn,\n",
        "                                start_date, end_date, start_dateYOY, end_dateYOY, dimColumnOne)\n",
        "    print(\"\\n6. Created current and previous year tables\")\n",
        "    del end_date, start_date, start_dateYOY, end_dateYOY\n",
        "\n",
        "    # Create Columns Item\n",
        "    cols = dfThen.columns\n",
        "\n",
        "    # Create Categories\n",
        "    dfCategories = intersection(dfThen.index.get_level_values(\n",
        "    \t1).unique(), dfNow.index.get_level_values(1).unique())\n",
        "\n",
        "    # Create Category Counter - Set to 0\n",
        "    categoryCounter = 0  # IS THIS NECESSARY?=['/]\n",
        "\n",
        "    # Create Initial Data Frame\n",
        "    tempFrames = []\n",
        "\n",
        "    # Error Handling, print my list of categories\n",
        "    print(dfCategories)\n",
        "    print('\\n6. Begin looping through dimension')\n",
        "\n",
        "    # Loop Through\n",
        "    for category in dfCategories:\n",
        "        print(\"running function: \", category)\n",
        "\n",
        "        # Current Year Data\n",
        "        dfTemp = dfNow.loc(axis=0)[pd.IndexSlice[:, category]].copy()\n",
        "        dfTempYOY = dfThen.loc(\n",
        "            axis=0)[pd.IndexSlice[:, category]].copy()   # YOY Data\n",
        "\n",
        "        # Current Year Data\n",
        "        dfTemp.reset_index(level=[1], inplace=True)\n",
        "        # YOY Data\n",
        "        dfTempYOY.reset_index(level=[1], inplace=True)\n",
        "\n",
        "        print(\"\\n\\n\\nAnomalies by \" +\n",
        "              dfTemp.columns[0] + \": \" + category + ' \\n')\n",
        "        # Current Year Data\n",
        "        dfTemp.drop(dfTemp.columns[0], axis=1, inplace=True)\n",
        "        # YOY Data\n",
        "        dfTempYOY.drop(dfTempYOY.columns[0], axis=1, inplace=True)\n",
        "        # Shift dates forward one day\n",
        "        dfTempYOY.index = dfTempYOY.index.shift(0, freq='D')\n",
        "        dfTempYOY = dfTempYOY.tail(30)\n",
        "        dfTemp = dfTemp.asfreq('D').fillna(0)  # FillNA with O\n",
        "        dfTempYOY = dfTempYOY.asfreq('D').fillna(0)  # FillNA with O\n",
        "\n",
        "        # Assign Series\n",
        "        series = dfTemp\n",
        "        seriesYOY = dfTempYOY\n",
        "        #print(series)\n",
        "        #print(seriesYOY)\n",
        "\n",
        "        if len(series) > window:\n",
        "\n",
        "            # Set series\n",
        "            series = series.tail(series_length)\n",
        "\n",
        "            # Get rolling mean for current year\n",
        "            rolling_mean = series.rolling(window=window).mean()\n",
        "\n",
        "            # create Len of Series Test values\n",
        "            seriesLen = len(series)\n",
        "            seriesLenYOY = len(seriesYOY)\n",
        "\n",
        "            #shift index forward 1 year to overlay last year's data over current year's\n",
        "            seriesYOY.index = seriesYOY.index.shift(365, freq='D')\n",
        "            seriesYOY = seriesYOY.tail(series_length)\n",
        "\n",
        "            # Create YOY Rolling Mean\n",
        "            rolling_meanYOY = seriesYOY.rolling(window=window).mean()\n",
        "\n",
        "            # Create yoyTest Variable\n",
        "            if seriesLen == seriesLenYOY:  # Both Series are Equal, run current and YOY\n",
        "                yoyTest = True\n",
        "            elif seriesLen > seriesLenYOY:\n",
        "                yoyTest = False\n",
        "            elif seriesLen != seriesLenYOY:\n",
        "                yoyTest = False\n",
        "\n",
        "            # Create Bounds\n",
        "            upperBoundTierOne = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=1, lowerBound=False)\n",
        "            lowerBoundTierOne = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=1, lowerBound=True)\n",
        "\n",
        "            upperBoundTierTwo = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=2, lowerBound=False)\n",
        "            lowerBoundTierTwo = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=2, lowerBound=True)\n",
        "\n",
        "            upperBoundTierThree = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=3, lowerBound=False)\n",
        "            lowerBoundTierThree = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=3, lowerBound=True)\n",
        "\n",
        "            # Create YOY Bounds\n",
        "            if yoyTest == True:  # Create YOY if YOY Is True\n",
        "                upperBoundYOYTierOne = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=1, lowerBound=False)\n",
        "                lowerBoundYOYTierOne = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=1, lowerBound=True)\n",
        "                upperBoundYOYTierTwo = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=2, lowerBound=False)\n",
        "                lowerBoundYOYTierTwo = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=2, lowerBound=True)\n",
        "                upperBoundYOYTierThree = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=3, lowerBound=False)\n",
        "                lowerBoundYOYTierThree = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=3, lowerBound=True)\n",
        "            else:\n",
        "                replaceVal = series.copy()\n",
        "                #print(\"Copy: \", replaceVal)\n",
        "                replaceVal[metricColumn] = np.nan\n",
        "                #print(replaceVal)\n",
        "                upperBoundYOYTierOne = replaceVal\n",
        "                lowerBoundYOYTierOne = replaceVal\n",
        "                upperBoundYOYTierTwo = replaceVal\n",
        "                lowerBoundYOYTierTwo = replaceVal\n",
        "                upperBoundYOYTierThree = replaceVal\n",
        "                lowerBoundYOYTierThree = replaceVal\n",
        "\n",
        "            #print(series['sessions'])\n",
        "            #print(upperBoundYOYTierOne)\n",
        "\n",
        "            # Find Anomalies\n",
        "            # Tier One\n",
        "            allAnomaliesUpperTierOne = getAnomalies2(series, window, upperBoundTierOne, lowerBoundTierOne,\n",
        "                                                     upperBoundYOY=upperBoundYOYTierOne, lowerBoundYOY=lowerBoundYOYTierOne, lbound=False, isYOY=yoyTest)\n",
        "            allAnomaliesLowerTierOne = getAnomalies2(series, window, upperBoundTierOne, lowerBoundTierOne,\n",
        "                                                     upperBoundYOY=upperBoundYOYTierOne, lowerBoundYOY=lowerBoundYOYTierOne, lbound=True, isYOY=yoyTest)\n",
        "\n",
        "            # Tier Two\n",
        "            allAnomaliesUpperTierTwo = getAnomalies2(series, window, upperBoundTierTwo, lowerBoundTierTwo,\n",
        "                                                     upperBoundYOY=upperBoundYOYTierTwo, lowerBoundYOY=lowerBoundYOYTierTwo, lbound=False, isYOY=yoyTest)\n",
        "            allAnomaliesLowerTierTwo = getAnomalies2(series, window, upperBoundTierTwo, lowerBoundTierTwo,\n",
        "                                                     upperBoundYOY=upperBoundYOYTierTwo, lowerBoundYOY=lowerBoundYOYTierTwo, lbound=True, isYOY=yoyTest)\n",
        "\n",
        "            # Tier Three\n",
        "            allAnomaliesUpperTierThree = getAnomalies2(series, window, upperBoundTierThree, lowerBoundTierThree,\n",
        "                                                       upperBoundYOY=upperBoundYOYTierThree, lowerBoundYOY=lowerBoundYOYTierThree, lbound=False, isYOY=yoyTest)\n",
        "            allAnomaliesLowerTierThree = getAnomalies2(series, window, upperBoundTierThree, lowerBoundTierThree,\n",
        "                                                       upperBoundYOY=upperBoundYOYTierThree, lowerBoundYOY=lowerBoundYOYTierThree, lbound=True, isYOY=yoyTest)\n",
        "\n",
        "            # Create temp output DF\n",
        "            finaldf = series.copy()\n",
        "            del series\n",
        "            #print(\"series copy: \", finaldf)\n",
        "\n",
        "            # Add Current Year Bounds to output df\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundTierOne, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundTierTwo, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundTierThree, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundTierOne, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundTierTwo, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundTierThree, left_index=True, right_index=True)\n",
        "            #print(\"add bounds: \", finaldf)\n",
        "            del upperBoundTierOne, upperBoundTierTwo, upperBoundTierThree, lowerBoundTierOne, lowerBoundTierTwo, lowerBoundTierThree\n",
        "\n",
        "            # Add YOY Bounds to output df\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundYOYTierOne, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundYOYTierTwo, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundYOYTierThree, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundYOYTierOne, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundYOYTierTwo, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundYOYTierThree, left_index=True, right_index=True)\n",
        "            del upperBoundYOYTierOne, upperBoundYOYTierTwo, upperBoundYOYTierThree, lowerBoundYOYTierOne, lowerBoundYOYTierTwo, lowerBoundYOYTierThree\n",
        "\n",
        "            # Drop extra anomaly column that I honestly don't know what it exists for\n",
        "            dropCol = allAnomaliesUpperTierOne.columns.values.tolist()[-1]\n",
        "            allAnomaliesUpperTierOne = allAnomaliesUpperTierOne.drop([dropCol],axis=1)\n",
        "            allAnomaliesUpperTierTwo = allAnomaliesUpperTierTwo.drop([dropCol],axis=1)\n",
        "            allAnomaliesUpperTierThree = allAnomaliesUpperTierThree.drop([dropCol],axis=1)\n",
        "            allAnomaliesLowerTierOne = allAnomaliesLowerTierOne.drop([dropCol],axis=1)\n",
        "            allAnomaliesLowerTierTwo = allAnomaliesLowerTierTwo.drop([dropCol],axis=1)\n",
        "            allAnomaliesLowerTierThree = allAnomaliesLowerTierThree.drop([dropCol],axis=1)\n",
        "            #print(\"check anomalies tier one upper: \", allAnomaliesUpperTierOne)\n",
        "\n",
        "            # Merge in the anomalies\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesUpperTierOne, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesUpperTierTwo, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesUpperTierThree, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesLowerTierOne, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesLowerTierTwo, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesLowerTierThree, left_index=True, right_index=True, how=\"left\")\n",
        "            #print(\"add anomalies: \", finaldf)\n",
        "            del allAnomaliesUpperTierOne, allAnomaliesUpperTierTwo, allAnomaliesUpperTierThree, allAnomaliesLowerTierOne, allAnomaliesLowerTierTwo, allAnomaliesLowerTierThree\n",
        "\n",
        "            # Rename Columns\n",
        "            finaldf.columns = ['actuals',\n",
        "                               'upperBoundTierOne', 'upperBoundTierTwo', 'upperBoundTierThree',\n",
        "                               'lowerBoundTierOne', 'lowerBoundTierTwo', 'lowerBoundTierThree',\n",
        "                               'upperBoundYOYTierOne', 'upperBoundYOYTierTwo', 'upperBoundYOYTierThree',\n",
        "                               'lowerBoundYOYTierOne', 'lowerBoundYOYTierTwo', 'lowerBoundYOYTierThree',\n",
        "                               'allAnomaliesUpperTierOne', 'allAnomaliesUpperTierTwo', 'allAnomaliesUpperTierThree', 'allAnomaliesLowerTierOne', 'allAnomaliesLowerTierTwo', 'allAnomaliesLowerTierThree']\n",
        "\n",
        "            finaldf[dimColumnOne] = category\n",
        "\n",
        "            finaldf.reset_index()\n",
        "\n",
        "            print(\"Shape of dataframe: \", finaldf.shape)\n",
        "\n",
        "            tempFrames.append(finaldf)\n",
        "\n",
        "        else:\n",
        "            print(\"Category won't run, moving on\", category)\n",
        "    #print(\"TEMP FRAMES SHAPE: \", tempFrames)\n",
        "    outputDF = pd.concat(tempFrames)\n",
        "    print('\\n7. Table finished populating - saving')\n",
        "\n",
        "    return outputDF\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn04jRlsit1D",
        "colab_type": "text"
      },
      "source": [
        "# Run the Handler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDg93h8PivXA",
        "colab_type": "code",
        "outputId": "c3dd6686-1dc8-47b2-97db-d61f458d5cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "handler(dfbq,colToClean,dateColumn,dimColumnOne,dimColumnTwo,metricColumn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. BigQuery Table Collected\n",
            "\n",
            "2. Data Frame Created\n",
            "\n",
            "4. Filtered data to top  100 landingPage\n",
            "\n",
            "5. Created Data ranges\n",
            "\n",
            "6. Created current and previous year tables\n",
            "['www.cbtnuggets.com/learn', 'www.cbtnuggets.com/search', '(not set)', 'www.cbtnuggets.com/login', 'www.cbtnuggets.com/']\n",
            "\n",
            "6. Begin looping through dimension\n",
            "running function:  www.cbtnuggets.com/learn\n",
            "\n",
            "\n",
            "\n",
            "Anomalies by landingPage: www.cbtnuggets.com/learn \n",
            "\n",
            "Shape of dataframe:  (30, 20)\n",
            "running function:  www.cbtnuggets.com/search\n",
            "\n",
            "\n",
            "\n",
            "Anomalies by landingPage: www.cbtnuggets.com/search \n",
            "\n",
            "Shape of dataframe:  (30, 20)\n",
            "running function:  (not set)\n",
            "\n",
            "\n",
            "\n",
            "Anomalies by landingPage: (not set) \n",
            "\n",
            "Shape of dataframe:  (30, 20)\n",
            "running function:  www.cbtnuggets.com/login\n",
            "\n",
            "\n",
            "\n",
            "Anomalies by landingPage: www.cbtnuggets.com/login \n",
            "\n",
            "Shape of dataframe:  (30, 20)\n",
            "running function:  www.cbtnuggets.com/\n",
            "\n",
            "\n",
            "\n",
            "Anomalies by landingPage: www.cbtnuggets.com/ \n",
            "\n",
            "Shape of dataframe:  (30, 20)\n",
            "\n",
            "7. Table finished populating - saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actuals</th>\n",
              "      <th>upperBoundTierOne</th>\n",
              "      <th>upperBoundTierTwo</th>\n",
              "      <th>upperBoundTierThree</th>\n",
              "      <th>lowerBoundTierOne</th>\n",
              "      <th>lowerBoundTierTwo</th>\n",
              "      <th>lowerBoundTierThree</th>\n",
              "      <th>upperBoundYOYTierOne</th>\n",
              "      <th>upperBoundYOYTierTwo</th>\n",
              "      <th>upperBoundYOYTierThree</th>\n",
              "      <th>lowerBoundYOYTierOne</th>\n",
              "      <th>lowerBoundYOYTierTwo</th>\n",
              "      <th>lowerBoundYOYTierThree</th>\n",
              "      <th>allAnomaliesUpperTierOne</th>\n",
              "      <th>allAnomaliesUpperTierTwo</th>\n",
              "      <th>allAnomaliesUpperTierThree</th>\n",
              "      <th>allAnomaliesLowerTierOne</th>\n",
              "      <th>allAnomaliesLowerTierTwo</th>\n",
              "      <th>allAnomaliesLowerTierThree</th>\n",
              "      <th>landingPage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>myDate</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-12-18</th>\n",
              "      <td>2454</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/learn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-19</th>\n",
              "      <td>2282</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/learn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-20</th>\n",
              "      <td>1789</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/learn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-21</th>\n",
              "      <td>1108</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/learn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-22</th>\n",
              "      <td>1304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/learn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-12</th>\n",
              "      <td>1373</td>\n",
              "      <td>2456.256181</td>\n",
              "      <td>2798.086227</td>\n",
              "      <td>3139.916272</td>\n",
              "      <td>1142.243819</td>\n",
              "      <td>800.413773</td>\n",
              "      <td>458.583728</td>\n",
              "      <td>5484.539896</td>\n",
              "      <td>6463.108201</td>\n",
              "      <td>7441.676507</td>\n",
              "      <td>1831.210104</td>\n",
              "      <td>852.641799</td>\n",
              "      <td>-125.926507</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-13</th>\n",
              "      <td>2358</td>\n",
              "      <td>2598.381181</td>\n",
              "      <td>2940.211227</td>\n",
              "      <td>3282.041272</td>\n",
              "      <td>1284.368819</td>\n",
              "      <td>942.538773</td>\n",
              "      <td>600.708728</td>\n",
              "      <td>5517.664896</td>\n",
              "      <td>6496.233201</td>\n",
              "      <td>7474.801507</td>\n",
              "      <td>1864.335104</td>\n",
              "      <td>885.766799</td>\n",
              "      <td>-92.801507</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-14</th>\n",
              "      <td>2380</td>\n",
              "      <td>2610.381181</td>\n",
              "      <td>2952.211227</td>\n",
              "      <td>3294.041272</td>\n",
              "      <td>1296.368819</td>\n",
              "      <td>954.538773</td>\n",
              "      <td>612.708728</td>\n",
              "      <td>5790.289896</td>\n",
              "      <td>6768.858201</td>\n",
              "      <td>7747.426507</td>\n",
              "      <td>2136.960104</td>\n",
              "      <td>1158.391799</td>\n",
              "      <td>179.823493</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-15</th>\n",
              "      <td>2330</td>\n",
              "      <td>2630.881181</td>\n",
              "      <td>2972.711227</td>\n",
              "      <td>3314.541272</td>\n",
              "      <td>1316.868819</td>\n",
              "      <td>975.038773</td>\n",
              "      <td>633.208728</td>\n",
              "      <td>5759.664896</td>\n",
              "      <td>6738.233201</td>\n",
              "      <td>7716.801507</td>\n",
              "      <td>2106.335104</td>\n",
              "      <td>1127.766799</td>\n",
              "      <td>149.198493</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-16</th>\n",
              "      <td>2199</td>\n",
              "      <td>2636.006181</td>\n",
              "      <td>2977.836227</td>\n",
              "      <td>3319.666272</td>\n",
              "      <td>1321.993819</td>\n",
              "      <td>980.163773</td>\n",
              "      <td>638.333728</td>\n",
              "      <td>5676.789896</td>\n",
              "      <td>6655.358201</td>\n",
              "      <td>7633.926507</td>\n",
              "      <td>2023.460104</td>\n",
              "      <td>1044.891799</td>\n",
              "      <td>66.323493</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>www.cbtnuggets.com/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            actuals  ...               landingPage\n",
              "myDate               ...                          \n",
              "2019-12-18     2454  ...  www.cbtnuggets.com/learn\n",
              "2019-12-19     2282  ...  www.cbtnuggets.com/learn\n",
              "2019-12-20     1789  ...  www.cbtnuggets.com/learn\n",
              "2019-12-21     1108  ...  www.cbtnuggets.com/learn\n",
              "2019-12-22     1304  ...  www.cbtnuggets.com/learn\n",
              "...             ...  ...                       ...\n",
              "2020-01-12     1373  ...       www.cbtnuggets.com/\n",
              "2020-01-13     2358  ...       www.cbtnuggets.com/\n",
              "2020-01-14     2380  ...       www.cbtnuggets.com/\n",
              "2020-01-15     2330  ...       www.cbtnuggets.com/\n",
              "2020-01-16     2199  ...       www.cbtnuggets.com/\n",
              "\n",
              "[150 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh0a0o5ZbwDh",
        "colab_type": "text"
      },
      "source": [
        "# SQL Handler - Do Not Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaE4-gu-Z8lI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def handlerwSQL(toClean=True, lpCount=100, series_length=365, window=8):\n",
        "\n",
        "    #Generate Query & initial table\n",
        "    client = bq.Client()\n",
        "    dfbq = client.query(sql, project=id).to_dataframe()\n",
        "    dfCopy = dfbq.copy()\n",
        "    del dfbq\n",
        "    print(\"1. BigQuery Table Collected\")\n",
        "\n",
        "    # Create Initial DataFrame - Cleaning Query Strings if Applicable\n",
        "    #def prepSingleDataFrame(df, clean, cleanCol, dateCol, metric, *dims):\n",
        "    df = prepSingleDataFrame(dfCopy, toClean, colToClean,\n",
        "                             dateColumn, metricColumn, dimColumnOne, dimColumnTwo)\n",
        "    print(\"\\n2. Data Frame Created\")\n",
        "\n",
        "    # Get Filter list for primary dimension\n",
        "    #focusList = focus(df, dimColumnOne, metricColumn, n=lpCount)\n",
        "    #print(\"\\n3. Focus list created of top \", lpCount, dimColumnOne)\n",
        "    \n",
        "\n",
        "    # Update table to only include focusList items\n",
        "    dfFiltered = filterDim(focusList, df, dimColumnOne)\n",
        "    print(\"\\n4. Filtered data to top \", lpCount, dimColumnOne)\n",
        "    del df\n",
        "\n",
        "    # Set Dates\n",
        "    end_date = pd.to_datetime(\n",
        "    \t(datetime.now() - timedelta(1)).strftime('%Y-%m-%d')).date()\n",
        "    start_date = pd.to_datetime(\n",
        "    \t(datetime.now() - timedelta(30)).strftime('%Y-%m-%d')).date()\n",
        "    start_dateYOY = pd.to_datetime(\n",
        "    \t(datetime.now() - timedelta(396)).strftime('%Y-%m-%d')).date()  # test at 396,365\n",
        "    end_dateYOY = pd.to_datetime(\n",
        "    \t(datetime.now() - timedelta(366)).strftime('%Y-%m-%d')).date()\n",
        "    print(\"\\n5. Created Data ranges\")\n",
        "\n",
        "    # Create Current Year Table and Previous Year Table\n",
        "    dfNow, dfThen = nowAndLater(dfFiltered, dateColumn, metricColumn,\n",
        "                                start_date, end_date, start_dateYOY, end_dateYOY, dimColumnOne)\n",
        "    print(\"\\n6. Created current and previous year tables\")\n",
        "    del end_date, start_date, start_dateYOY, end_dateYOY\n",
        "\n",
        "    # Create Columns Item\n",
        "    cols = dfThen.columns\n",
        "\n",
        "    # Create Categories\n",
        "    dfCategories = intersection(dfThen.index.get_level_values(\n",
        "    \t1).unique(), dfNow.index.get_level_values(1).unique())\n",
        "\n",
        "    # Create Category Counter - Set to 0\n",
        "    categoryCounter = 0  # IS THIS NECESSARY?=['/]\n",
        "\n",
        "    # Create Initial Data Frame\n",
        "    tempFrames = []\n",
        "\n",
        "    # Error Handling, print my list of categories\n",
        "    print(dfCategories)\n",
        "    print('\\n6. Begin looping through dimension')\n",
        "\n",
        "    # Loop Through\n",
        "    for category in dfCategories:\n",
        "        print(\"running function: \", category)\n",
        "\n",
        "        # Current Year Data\n",
        "        dfTemp = dfNow.loc(axis=0)[pd.IndexSlice[:, category]].copy()\n",
        "        dfTempYOY = dfThen.loc(\n",
        "            axis=0)[pd.IndexSlice[:, category]].copy()   # YOY Data\n",
        "\n",
        "        # Current Year Data\n",
        "        dfTemp.reset_index(level=[1], inplace=True)\n",
        "        # YOY Data\n",
        "        dfTempYOY.reset_index(level=[1], inplace=True)\n",
        "\n",
        "        print(\"\\n\\n\\nAnomalies by \" +\n",
        "              dfTemp.columns[0] + \": \" + category + ' \\n')\n",
        "        # Current Year Data\n",
        "        dfTemp.drop(dfTemp.columns[0], axis=1, inplace=True)\n",
        "        # YOY Data\n",
        "        dfTempYOY.drop(dfTempYOY.columns[0], axis=1, inplace=True)\n",
        "        # Shift dates forward one day\n",
        "        dfTempYOY.index = dfTempYOY.index.shift(0, freq='D')\n",
        "        dfTempYOY = dfTempYOY.tail(30)\n",
        "        dfTemp = dfTemp.asfreq('D').fillna(0)  # FillNA with O\n",
        "        dfTempYOY = dfTempYOY.asfreq('D').fillna(0)  # FillNA with O\n",
        "\n",
        "        # Assign Series\n",
        "        series = dfTemp\n",
        "        seriesYOY = dfTempYOY\n",
        "        #print(series)\n",
        "        #print(seriesYOY)\n",
        "\n",
        "        if len(series) > window:\n",
        "\n",
        "            # Set series\n",
        "            series = series.tail(series_length)\n",
        "\n",
        "            # Get rolling mean for current year\n",
        "            rolling_mean = series.rolling(window=window).mean()\n",
        "\n",
        "            # create Len of Series Test values\n",
        "            seriesLen = len(series)\n",
        "            seriesLenYOY = len(seriesYOY)\n",
        "\n",
        "            #shift index forward 1 year to overlay last year's data over current year's\n",
        "            seriesYOY.index = seriesYOY.index.shift(365, freq='D')\n",
        "            seriesYOY = seriesYOY.tail(series_length)\n",
        "\n",
        "            # Create YOY Rolling Mean\n",
        "            rolling_meanYOY = seriesYOY.rolling(window=window).mean()\n",
        "\n",
        "            # Create yoyTest Variable\n",
        "            if seriesLen == seriesLenYOY:  # Both Series are Equal, run current and YOY\n",
        "                yoyTest = True\n",
        "            elif seriesLen > seriesLenYOY:\n",
        "                yoyTest = False\n",
        "            elif seriesLen != seriesLenYOY:\n",
        "                yoyTest = False\n",
        "\n",
        "            # Create Bounds\n",
        "            upperBoundTierOne = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=1, lowerBound=False)\n",
        "            lowerBoundTierOne = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=1, lowerBound=True)\n",
        "\n",
        "            upperBoundTierTwo = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=2, lowerBound=False)\n",
        "            lowerBoundTierTwo = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=2, lowerBound=True)\n",
        "\n",
        "            upperBoundTierThree = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=3, lowerBound=False)\n",
        "            lowerBoundTierThree = getBounds(\n",
        "            \tseries, window, rolling_mean, scale=3, lowerBound=True)\n",
        "\n",
        "            # Create YOY Bounds\n",
        "            if yoyTest == True:  # Create YOY if YOY Is True\n",
        "                upperBoundYOYTierOne = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=1, lowerBound=False)\n",
        "                lowerBoundYOYTierOne = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=1, lowerBound=True)\n",
        "                upperBoundYOYTierTwo = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=2, lowerBound=False)\n",
        "                lowerBoundYOYTierTwo = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=2, lowerBound=True)\n",
        "                upperBoundYOYTierThree = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=3, lowerBound=False)\n",
        "                lowerBoundYOYTierThree = getBounds(\n",
        "                    seriesYOY, window, rolling_meanYOY, scale=3, lowerBound=True)\n",
        "            else:\n",
        "                replaceVal = series.copy()\n",
        "                #print(\"Copy: \", replaceVal)\n",
        "                replaceVal[metricColumn] = np.nan\n",
        "                #print(replaceVal)\n",
        "                upperBoundYOYTierOne = replaceVal\n",
        "                lowerBoundYOYTierOne = replaceVal\n",
        "                upperBoundYOYTierTwo = replaceVal\n",
        "                lowerBoundYOYTierTwo = replaceVal\n",
        "                upperBoundYOYTierThree = replaceVal\n",
        "                lowerBoundYOYTierThree = replaceVal\n",
        "\n",
        "            #print(series['sessions'])\n",
        "            #print(upperBoundYOYTierOne)\n",
        "\n",
        "            # Find Anomalies\n",
        "            # Tier One\n",
        "            allAnomaliesUpperTierOne = getAnomalies2(series, window, upperBoundTierOne, lowerBoundTierOne,\n",
        "                                                     upperBoundYOY=upperBoundYOYTierOne, lowerBoundYOY=lowerBoundYOYTierOne, lbound=False, isYOY=yoyTest)\n",
        "            allAnomaliesLowerTierOne = getAnomalies2(series, window, upperBoundTierOne, lowerBoundTierOne,\n",
        "                                                     upperBoundYOY=upperBoundYOYTierOne, lowerBoundYOY=lowerBoundYOYTierOne, lbound=True, isYOY=yoyTest)\n",
        "\n",
        "            # Tier Two\n",
        "            allAnomaliesUpperTierTwo = getAnomalies2(series, window, upperBoundTierTwo, lowerBoundTierTwo,\n",
        "                                                     upperBoundYOY=upperBoundYOYTierTwo, lowerBoundYOY=lowerBoundYOYTierTwo, lbound=False, isYOY=yoyTest)\n",
        "            allAnomaliesLowerTierTwo = getAnomalies2(series, window, upperBoundTierTwo, lowerBoundTierTwo,\n",
        "                                                     upperBoundYOY=upperBoundYOYTierTwo, lowerBoundYOY=lowerBoundYOYTierTwo, lbound=True, isYOY=yoyTest)\n",
        "\n",
        "            # Tier Three\n",
        "            allAnomaliesUpperTierThree = getAnomalies2(series, window, upperBoundTierThree, lowerBoundTierThree,\n",
        "                                                       upperBoundYOY=upperBoundYOYTierThree, lowerBoundYOY=lowerBoundYOYTierThree, lbound=False, isYOY=yoyTest)\n",
        "            allAnomaliesLowerTierThree = getAnomalies2(series, window, upperBoundTierThree, lowerBoundTierThree,\n",
        "                                                       upperBoundYOY=upperBoundYOYTierThree, lowerBoundYOY=lowerBoundYOYTierThree, lbound=True, isYOY=yoyTest)\n",
        "\n",
        "            # Create temp output DF\n",
        "            finaldf = series.copy()\n",
        "            del series\n",
        "            #print(\"series copy: \", finaldf)\n",
        "\n",
        "            # Add Current Year Bounds to output df\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundTierOne, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundTierTwo, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundTierThree, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundTierOne, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundTierTwo, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundTierThree, left_index=True, right_index=True)\n",
        "            #print(\"add bounds: \", finaldf)\n",
        "            del upperBoundTierOne, upperBoundTierTwo, upperBoundTierThree, lowerBoundTierOne, lowerBoundTierTwo, lowerBoundTierThree\n",
        "\n",
        "            # Add YOY Bounds to output df\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundYOYTierOne, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundYOYTierTwo, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tupperBoundYOYTierThree, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundYOYTierOne, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundYOYTierTwo, left_index=True, right_index=True)\n",
        "            finaldf = finaldf.merge(\n",
        "            \tlowerBoundYOYTierThree, left_index=True, right_index=True)\n",
        "            del upperBoundYOYTierOne, upperBoundYOYTierTwo, upperBoundYOYTierThree, lowerBoundYOYTierOne, lowerBoundYOYTierTwo, lowerBoundYOYTierThree\n",
        "\n",
        "            # Drop extra anomaly column that I honestly don't know what it exists for\n",
        "            dropCol = allAnomaliesUpperTierOne.columns.values.tolist()[-1]\n",
        "            allAnomaliesUpperTierOne = allAnomaliesUpperTierOne.drop([dropCol],axis=1)\n",
        "            allAnomaliesUpperTierTwo = allAnomaliesUpperTierTwo.drop([dropCol],axis=1)\n",
        "            allAnomaliesUpperTierThree = allAnomaliesUpperTierThree.drop([dropCol],axis=1)\n",
        "            allAnomaliesLowerTierOne = allAnomaliesLowerTierOne.drop([dropCol],axis=1)\n",
        "            allAnomaliesLowerTierTwo = allAnomaliesLowerTierTwo.drop([dropCol],axis=1)\n",
        "            allAnomaliesLowerTierThree = allAnomaliesLowerTierThree.drop([dropCol],axis=1)\n",
        "            #print(\"check anomalies tier one upper: \", allAnomaliesUpperTierOne)\n",
        "\n",
        "            # Merge in the anomalies\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesUpperTierOne, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesUpperTierTwo, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesUpperTierThree, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesLowerTierOne, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesLowerTierTwo, left_index=True, right_index=True, how=\"left\")\n",
        "            finaldf = finaldf.merge(\n",
        "            \tallAnomaliesLowerTierThree, left_index=True, right_index=True, how=\"left\")\n",
        "            #print(\"add anomalies: \", finaldf)\n",
        "            del allAnomaliesUpperTierOne, allAnomaliesUpperTierTwo, allAnomaliesUpperTierThree, allAnomaliesLowerTierOne, allAnomaliesLowerTierTwo, allAnomaliesLowerTierThree\n",
        "\n",
        "            # Rename Columns\n",
        "            finaldf.columns = ['actuals',\n",
        "                               'upperBoundTierOne', 'upperBoundTierTwo', 'upperBoundTierThree',\n",
        "                               'lowerBoundTierOne', 'lowerBoundTierTwo', 'lowerBoundTierThree',\n",
        "                               'upperBoundYOYTierOne', 'upperBoundYOYTierTwo', 'upperBoundYOYTierThree',\n",
        "                               'lowerBoundYOYTierOne', 'lowerBoundYOYTierTwo', 'lowerBoundYOYTierThree',\n",
        "                               'allAnomaliesUpperTierOne', 'allAnomaliesUpperTierTwo', 'allAnomaliesUpperTierThree', 'allAnomaliesLowerTierOne', 'allAnomaliesLowerTierTwo', 'allAnomaliesLowerTierThree']\n",
        "\n",
        "            finaldf[dimColumnOne] = category\n",
        "\n",
        "            finaldf.reset_index()\n",
        "\n",
        "            print(\"Shape of dataframe: \", finaldf.shape)\n",
        "\n",
        "            tempFrames.append(finaldf)\n",
        "\n",
        "        else:\n",
        "            print(\"Category won't run, moving on\", category)\n",
        "    #print(\"TEMP FRAMES SHAPE: \", tempFrames)\n",
        "    outputDF = pd.concat(tempFrames)\n",
        "    print('\\n7. Table finished populating - writing to BQ')\n",
        "\n",
        "    ## WRITE TO BQ ##\n",
        "    # Since string columns use the \"object\" dtype, pass in a (partial) schema\n",
        "    # to ensure the correct BigQuery data type.\n",
        "    job_config = bigquery.LoadJobConfig(schema=[\n",
        "        bigquery.SchemaField(\"myDate\", \"DATE\"),\n",
        "        bigquery.SchemaField(\"actuals\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"upperBoundTierOne\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"upperBoundTierTwo\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"upperBoundTierThree\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"lowerBoundTierOne\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"lowerBoundTierTwo\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"lowerBoundTierThree\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"upperBoundYOYTierOne\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"upperBoundYOYTierTwo\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"upperBoundYOYTierThree\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"lowerBoundYOYTierOne\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"lowerBoundYOYTierTwo\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"lowerBoundYOYTierThree\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"allAnomaliesUpperTierOne\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"allAnomaliesUpperTierTwo\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"allAnomaliesUpperTierThree\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"allAnomaliesLowerTierOne\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"allAnomaliesLowerTierTwo\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"allAnomaliesLowerTierThree\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(dimColumnOne, \"STRING\")\n",
        "    ],\n",
        "        write_disposition=\"WRITE_TRUNCATE\")\n",
        "\n",
        "    job = client.load_table_from_dataframe(\n",
        "        outputDF, finalTable, job_config=job_config\n",
        "    )\n",
        "\n",
        "    # Wait for the load job to complete.\n",
        "    job.result()\n",
        "    print('\\n8. Written to BQ')\n",
        "\n",
        "    return outputDF\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}